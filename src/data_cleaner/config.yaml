# 云锦图片数据清洗工具配置文件
# 路径说明：支持绝对路径和相对路径（相对于项目根目录）

# ==================== 基础配置 ====================
# 输入目录（爬虫输出的原始图片目录）
input_dir: "D:\\codes\\yunjin_data\\output"

# 输出目录（清洗后图片存放目录）
output_dir: "D:\\codes\\yunjin_data\\output\\cleaned"

# 处理模式：quality(仅质量)、style(仅风格)、full(完整)
mode: "full"

# 是否生成清洗报告
generate_report: true

# 目标输出尺寸（所有图片统一缩放到此尺寸）
target_width: 512
target_height: 512

# 缩放模式：
#   'stretch' - 强制拉伸到目标尺寸（会改变宽高比，不推荐）
#   'fit' - 等比例缩放+填充（保持宽高比，推荐用于训练数据）
#   'crop' - 等比例缩放+中心裁剪（保持宽高比，会裁剪部分内容）
resize_mode: "fit"


# ==================== 质量检查配置 ====================
quality:
  # 最小分辨率要求（SD1.5推荐最小尺寸）
  min_width: 512
  min_height: 512

  # 模糊度阈值（Laplacian方差，越高越清晰）
  blur_threshold: 50.0

  # 是否检查Alpha通道
  check_alpha_channel: true

  # 是否检查图片损坏
  check_corruption: true


# ==================== 风格分类配置 ====================
style:
  # 云锦置信度阈值，大于此值认为是云锦
  style_threshold: 0.65

  # 人工复核阈值，小于此值直接拒绝
  review_threshold: 0.40

  # CLIP模型名称
  clip_model_name: "D:\\models\\clip-vit-base-patch32"

  # 是否使用GPU
  use_gpu: true

  # 批量推理大小
  batch_size: 32


# ==================== 自动标注配置 ====================
caption:
  # 是否启用自动标注
  enabled: true

  # BLIP模型名称
  blip_model_name: "D:\\models\\blip-image-captioning-base"

  # 是否使用GPU
  use_gpu: true

  # Caption最大长度
  max_length: 70

  # Caption前缀（必需，用于SD1.5 LoRA训练的触发词）
  # 前缀会添加到所有生成的caption前面，确保模型学习到"cloud brocade"概念
  caption_prefix: "cloud brocade, traditional Chinese textile"

  # 默认caption（当生成失败时使用）
  default_caption: "cloud brocade, traditional Chinese textile"


# ==================== 输出子目录配置 ====================
output_subdirs:
  approved: "approved"
  rejected_quality: "rejected_quality"
  rejected_style: "rejected_style"
  review: "review"
  reports: "reports"
